# Draft: Sub-2 ms Video Pipeline — Wi-Fi MAC-Level Bypass to Direct Display

## Date: 2025-08-08

---

## Abstract / 摘要

**English**  
Current wireless video streaming pipelines typically incur total latencies of 20–50 ms, with even wired links rarely dropping below 10 ms. In many latency-sensitive applications such as cloud gaming, VR, industrial control, and remote surgery, this delay can severely degrade user experience and system responsiveness.

This work targets the processing pipeline latency **excluding** network transmission time, defined as the time from when the sender’s application layer triggers the rendering pipeline to when the decoded first pixel is ready in the receiver’s display controller buffer. We propose an end-to-end processing architecture that bypasses conventional OS networking and graphics stacks: Wi-Fi MAC-level packet diversion, AF_XDP kernel bypass with zero-copy delivery to user space, line-based decoding, and direct display-controller scan-out (GPU optional).

Preliminary design analysis suggests that, under controlled hardware conditions on Linux-based mobile or embedded devices, it is feasible to reduce this processing latency to ≤ 2 ms. We summarize related research, present a system architecture, outline experimental methodologies, and discuss challenges and application scenarios for such an ultra-low-latency pipeline.

**中文**  
当前无线视频传输链路的总延迟通常在 20–50 毫秒之间，即便有线链路也很少低于 10 毫秒。在云游戏、VR、工业控制、远程医疗等对延迟高度敏感的应用中，这种延迟会显著降低用户体验与系统响应速度。

本文关注的目标是不包含网络传输时间的处理链路延迟，定义为：从发送端应用层触发渲染管线开始，到接收端解码后首像素进入显示控制器缓冲区为止。我们提出了一种绕过传统操作系统网络与图形栈的端到端处理架构：Wi-Fi MAC 层数据分流、基于 AF_XDP 的内核旁路与零拷贝用户态传递、行级解码，以及显示控制器直扫（GPU 可选）。

初步设计分析表明，在基于 Linux 内核的通用移动或嵌入式设备的受控硬件条件下，有可能将此处理链路延迟压缩至 ≤ 2 毫秒。本文将综述相关研究，提出系统架构，给出实验方法，并讨论此类超低延迟链路在应用与实现中的挑战。

---

## 1. Introduction / 引言

### 1.1 Background and Motivation / 背景与动机

**English**  
In real-time interactive applications such as cloud gaming, VR/AR, industrial automation, and remote surgery, end-to-end latency directly impacts usability and user experience. While network transmission delay is an important component, the processing latency on the sender and receiver sides — including rendering, encoding, decoding, and display — can also introduce significant delays.

Conventional wireless video pipelines, especially over Wi-Fi, often rely on the full OS networking stack and the complete graphics composition path. These introduce multiple buffer copies, scheduling delays, and synchronization waits, resulting in processing latencies of several to tens of milliseconds even under ideal network conditions. This means that even if network latency is minimized, the overall system responsiveness remains limited by the processing path.

**中文**  
在云游戏、VR/AR、工业自动化、远程医疗等实时交互类应用中，端到端延迟直接影响可用性与用户体验。虽然网络传输延迟是总延迟的重要组成部分，但发送端与接收端的处理延迟——包括渲染、编码、解码与显示——同样可能引入显著的时间消耗。

传统的无线视频传输链路，尤其是在 Wi-Fi 环境下，通常依赖完整的操作系统网络协议栈和全套图形合成路径。这会带来多次缓冲区拷贝、调度延迟以及同步等待，即使在理想的网络条件下，处理链路的延迟依然可能达到数毫秒到数十毫秒。这意味着，即便网络延迟被压缩到最低，系统的整体响应速度依然受限于处理链路本身。

---

### 1.2 Scope and Goal / 研究范围与目标

**English**  
This work covers the end-to-end processing pipeline latency excluding network transmission time, spanning both the sender and receiver. The measurement window starts when the sender’s application layer triggers the rendering pipeline and ends when the decoded first pixel is ready in the receiver’s display controller buffer.

On the **sender** side, the focus is on achieving minimal capture-to-encode latency through:
- Selecting low-latency codecs (e.g., JPEG XS) with support for line- or slice-based output  
- Minimizing encoding pipeline buffering and avoiding frame-level waits  
- Designing transport encapsulation (e.g., lightweight RTP, custom framing) that delivers decodable segments to the receiver as early as possible

On the **receiver** side, the goal is to process incoming data with ≤ 2 ms latency — from network interface to display controller — by bypassing conventional OS networking and graphics stacks, employing zero-copy transfer paths, and using line-based decode with direct display scan-out (GPU optional). The architecture targets Linux-based mobile or embedded devices, minimizing dependencies on platform-specific composition layers.

**中文**  
本文研究的不包含网络传输时间的端到端处理链路延迟，范围涵盖发送端与接收端。测量窗口定义为：从发送端应用层触发渲染管线开始，到接收端解码后首像素进入显示控制器缓冲区为止。

在**发送端**，我们重点关注通过以下方式实现最小的采集到编码延迟：
- 选择支持行级或片段级输出的低延迟编解码器（如 JPEG XS）  
- 最小化编码管线缓冲，避免整帧级等待  
- 设计轻量化的传输封装（如精简化 RTP、自定义帧格式），确保解码所需的数据尽早送达接收端

在**接收端**，我们的目标是在网络接口到显示控制器的处理路径中实现稳定的 ≤ 2 毫秒 延迟。这包括绕过传统操作系统网络与图形栈、采用零拷贝数据传递、并利用行级解码与显示控制器直扫（GPU 可选）。该架构面向基于 Linux 内核的通用移动或嵌入式设备，尽量减少对特定平台合成层的依赖。

---

### 1.3 Contributions / 本文贡献

**English**  
The main contributions of this work are as follows:
1. **End-to-end sub-2 ms processing pipeline design (excluding network delay)** — Complete architecture from application-layer rendering trigger to decoded first pixel in display controller buffer.  
2. **MAC-level bypass and zero-copy integration** — Combining Wi-Fi MAC-layer packet diversion with AF_XDP kernel bypass to eliminate redundant buffering and copying.  
3. **Line-based decode and direct display-controller scan-out** — Enabling decode and display preparation to proceed in parallel, bypassing conventional composition layers, optionally avoiding GPU involvement.  
4. **Reproducible measurement and validation framework** — Clearly defined latency measurement points and module/full-pipeline experiments for reproducible performance validation.

**中文**  
本文的主要贡献如下：
1. **端到端亚 2 毫秒处理链路设计（不含网络延迟）** —— 从应用层渲染触发到解码后首像素进入显示控制器缓冲区的完整架构。  
2. **MAC 层旁路与零拷贝结合** —— 将 Wi-Fi MAC 层数据分流与基于 AF_XDP 的内核旁路结合，消除操作系统网络协议栈中的冗余缓冲与拷贝。  
3. **行级解码与显示控制器直扫** —— 支持解码与显示准备并行进行，绕过传统合成层，并在可行时避免 GPU 参与。  
4. **可复现的延迟测量与验证框架** —— 精确定义延迟测量点，并提供模块级与全链路实验方案，确保性能验证结果可复现。




### 4.1

[Sender: Application Layer]
           │
           ▼
  ┌───────────────────────┐
  │ Rendering / Capture    │
  └───────────────────────┘
           │
           ▼
  ┌───────────────────────┐
  │ Encoder (Line/Slice)   │
  └───────────────────────┘
           │
           ▼
  ┌───────────────────────┐
  │ Transport Encapsulation│
  │ (Lightweight RTP/Custom│
  │  framing)               │
  └───────────────────────┘
           │
    (Network Transmission)
           │
           ▼
  ┌───────────────────────┐
  │ MAC-Level Bypass       │
  │ (Wi-Fi Firmware Split) │
  └───────────────────────┘
           │
           ▼
  ┌───────────────────────┐
  │ AF_XDP Zero-Copy       │
  │ Buffer Management      │
  └───────────────────────┘
           │
           ▼
  ┌───────────────────────┐
  │ Line-Based Decode      │
  └───────────────────────┘
           │
           ▼
  ┌───────────────────────┐
  │ Display Controller     │
  │ (KMS Plane Import)     │
  └───────────────────────┘

### 4.4 Line-based Decode → Direct Scan-out via Display Controller (GPU optional)

**目标**：将解码后的像素数据以最少拷贝、最短路径交给显示控制器（KMS/DRM），避免经过完整图形栈和 GPU 合成；GPU 仅在需要像素格式/色域转换或 blit 时参与。

**路径概述**

1. **接收与搬运**：NIC → AF_XDP → 用户态环形队列（零拷贝）；用户态将码流直接提交给硬件解码器或零拷贝映射的解码输入缓冲。
2. **行级解码（以 JPEG XS 为例）**：解码器以行/条带（stripes）为粒度输出，边解码边写入**预先分配且可被 KMS 导入的 dma-buf**（物理连续或 IOMMU 映射）。
3. **直扫显示**：显示控制器的 **plane** 直接 **import dma-buf** 作为 framebuffer，发起 **atomic commit**；若控制器支持对同一 FB 的滚动式写入 + 扫描，首行可在极短时间内被扫描到面板。

- For scenarios requiring additional on-screen UI (e.g., controls, status overlays),  
  a separate hardware overlay plane is used. The video plane receives the decoded 
  stream via zero-copy direct scan-out, while the UI plane is rendered by the GPU.  
  Both planes are composited at the display-controller level to avoid introducing 
  GPU compositing delay into the video path.
在需要额外 UI 展示（如控制按钮、状态信息、提示框）的场景中，采用独立的硬件 Overlay Plane。视频 Plane 通过零拷贝直扫接收解码流，UI Plane 则由 GPU 渲染并输入显示控制器。在显示控制器层完成两个 plane 的合成，避免将 GPU 合成延迟引入视频主路径。

4. **GPU 可选**：仅当显示控制器不支持解码输出的像素格式（如 10-bit 4:2:2）或需要 colorspace 转换时，使用 GPU 作为“快速 blitter/format converter”。此时仍应使用 dma-buf/GBM/EGLStreams 等保持零拷贝。

**实现要点**

- **缓冲区生命周期**：用 dma-buf 导出/导入，避免用户态再拷贝；为减少同步等待，采用固定大小的帧缓池，配合 fence/timeline 同步。
- **格式与对齐**：优先选择显示控制器原生支持的像素格式（如 RGB888、XRGB8888、NV12 等），避免额外 blit。
- **扫描与时序**：若控制器/面板要求帧边界更新（vblank），需在 vblank 前完成顶行写入并原子提交；若硬件允许 finer-grained 更新（如支持 TE/partial refresh/rolling update），可进一步减少“首像素”等待。
- **回退路径**：当解码器输出格式与 plane 不兼容时，启用最小成本的 GPU blit/CSC，但仍保持零拷贝（dma-buf in/out），避免 CPU 参与。

**JPEG XS 特别说明**

- JPEG XS 支持**低复杂度、极低时延**与 **行/条带级流水**处理，适合“接收 → 解码 → 扫描”三段并行。
- 推荐：硬件解码（VPU/FPGA/ASIC）直接写入 **KMS 可导入的 dma-buf**；软件解码仅适用于低分辨率或原型验证。
- 若解码输出为 YUV 平面格式且面板/控制器仅支持 RGB 扫描：优先寻找控制器端的 **YUV plane** 支持；其次才考虑 GPU 做 **YUV→RGB** 转换（零拷贝）。

**测量与可见像素**

- 由于多数面板按行扫描，**首像素出现时间**取决于：  
  (i) 顶部若干行在下一次 vblank 之前已写入并提交；  
  (ii) 控制器是否允许帧中期更替（partial/rolling）。
- 建议通过 **TE/vsync 中断** 或 **光电二极管** 配合屏幕顶部亮度变化测首像素时间（详见 §5.1）。
